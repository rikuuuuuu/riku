{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import numpy as np\n",
    "from libsvm.svmutil import *  \n",
    "from libsvm.svm import *  \n",
    "from sklearn import svm\n",
    "from PIL import Image \n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "from sklearn import decomposition\n",
    "from scipy.ndimage import binary_hit_or_miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingSampleNum = 2000 # 学習サンプル総数\n",
    "TestSampleNum = 10000 # テストサンプル総数\n",
    "ClassNum = 10 # クラス数（今回は10）\n",
    "ImageSize = 28 # 画像サイズ（今回は縦横ともに28）\n",
    "TrainingDataFile = './Images/TrainingSamples/{0:1d}-{1:04d}.png'\n",
    "TestDataFile = './Images/TestSamples/{0:1d}-{1:04d}.png'\n",
    "#OutFile = './Images/OutSamples/gray_{0:1d}-{1:04d}.png' \n",
    "#TrainingDataFile = './Images/OutSamples/gray_{0:1d}-{1:04d}.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def pca(dataMat, dataNum):\n",
    "    #k = 300\n",
    "    #New_dataMat = np.zeros((dataNum, k))\n",
    "    #pca = decomposition.PCA(n_components = k)\n",
    "    #New_dataMat = pca.fit_transform(dataMat)\n",
    "    #return New_dataMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Zhang_Suen_thinning(binary_image):\n",
    "    # オリジナルの画像をコピー\n",
    "    image_thinned = binary_image.copy()\n",
    "    # 初期化します。この値は次のwhile文の中で除かれます。\n",
    "    changing_1 = changing_2 = [1]\n",
    "    while changing_1 or changing_2:\n",
    "        # ステップ1\n",
    "        changing_1 = []\n",
    "        rows, columns = image_thinned.shape\n",
    "        for x in range(1, rows - 1):\n",
    "            for y in range(1, columns -1):\n",
    "                p2, p3, p4, p5, p6, p7, p8, p9 = neighbour_points = neighbours(x, y, image_thinned)\n",
    "                if (image_thinned[x][y] == 1 and\n",
    "                    2 <= sum(neighbour_points) <= 6 and # 条件2\n",
    "                    count_transition(neighbour_points) == 1 and # 条件3\n",
    "                    p2 * p4 * p6 == 0 and # 条件4\n",
    "                    p4 * p6 * p8 == 0): # 条件5\n",
    "                    changing_1.append((x,y))\n",
    "        for x, y in changing_1:\n",
    "            image_thinned[x][y] = 0\n",
    "        # ステップ2\n",
    "        changing_2 = []\n",
    "        for x in range(1, rows - 1):\n",
    "            for y in range(1, columns -1):\n",
    "                p2, p3, p4, p5, p6, p7, p8, p9 = neighbour_points = neighbours(x, y, image_thinned)\n",
    "                if (image_thinned[x][y] == 1 and\n",
    "                    2 <= sum(neighbour_points) <= 6 and # 条件2\n",
    "                    count_transition(neighbour_points) == 1 and # 条件3\n",
    "                    p2 * p4 * p8 == 0 and # 条件4\n",
    "                    p2 * p6 * p8 == 0): # 条件5\n",
    "                    changing_2.append((x,y))\n",
    "        for x, y in changing_2:\n",
    "            image_thinned[x][y] = 0        \n",
    "    return image_thinned\n",
    "\n",
    "\n",
    "# 2値画像の黒を1、白を0とするように変換するメソッドです\n",
    "#def black_one(binary):\n",
    "   # bool_image = binary.astype(bool)\n",
    "    #inv_bool_image = ~bool_image\n",
    "    #return inv_bool_image.astype(int)\n",
    "\n",
    "# 画像の外周を0で埋めるメソッドです\n",
    "def padding_zeros(image):\n",
    "    import numpy as np\n",
    "    m,n = np.shape(image)\n",
    "    padded_image = np.zeros((m+2,n+2))\n",
    "    padded_image[1:-1,1:-1] = image\n",
    "    return padded_image\n",
    "\n",
    "# 外周1行1列を除くメソッドです。\n",
    "def unpadding(image):\n",
    "    return image[1:-1, 1:-1]\n",
    "\n",
    "# 指定されたピクセルの周囲のピクセルを取得するメソッドです\n",
    "def neighbours(x, y, image):\n",
    "    return [image[x-1][y], image[x-1][y+1], image[x][y+1], image[x+1][y+1], # 2, 3, 4, 5\n",
    "             image[x+1][y], image[x+1][y-1], image[x][y-1], image[x-1][y-1]] # 6, 7, 8, 9\n",
    "\n",
    "# 0→1の変化の回数を数えるメソッドです\n",
    "#def count_transition(neighbours):\n",
    "    #neighbours += neighbours[:1]\n",
    "    #return sum( (n1, n2) == (0, 1) for n1, n2 in zip(neighbours, neighbours[1:]) )\n",
    "\n",
    "# 黒を1、白を0とする画像を、2値画像に戻すメソッドです\n",
    "#def inv_black_one(inv_bool_image):\n",
    "    #bool_image = ~inv_bool_image.astype(bool)\n",
    "    #return bool_image.astype(int) * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2vector(imgFile, thres):\n",
    "    img = Image.open(imgFile).convert('L')\n",
    "    img_arr = np.array(img, 'i') # 20px * 20px 灰度图像\n",
    "    img_normlization = np.zeros(img_arr.shape, dtype=np.uint8)\n",
    "    for y in range(0, img_arr.shape[0]):\n",
    "        for x in range(0, img_arr.shape[1]):\n",
    "            if img_arr[y,x] < thres:\n",
    "                img_normlization[y,x] = 1\n",
    "            else:\n",
    "                img_normlization[y,x] = 0\n",
    "    #img_normlization = np.round(img_arr/255) # 对灰度值进行归一化\n",
    "    \n",
    "    img_arr2 = np.reshape(img_normlization, (1,-1))  # 1 * 784 矩阵\n",
    "    \n",
    "    #img_2 = padding_zeros(img_normlization)\n",
    "    #img_3 = Zhang_Suen_thinning(img_2)\n",
    "    #img_4 = unpadding(img_3)\n",
    "    #img_arr2 = np.reshape(img_4, (1,-1))  # 1 * 784 矩阵\n",
    "    return img_arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_convert(imgFileList, label):\n",
    "    dataLabel = [] # 存放类标签\n",
    "    dataNum = len(imgFileList)\n",
    "    dataMat = np.zeros((dataNum, 784)) # dataNum * 784 的矩阵\n",
    "    for i in range(dataNum):\n",
    "        imgName = imgFileList[i]\n",
    "        #imgName = get_img_name_str(imgNameStr)  # 得到 数字_实例编号.png\n",
    "        #print(\"imgName: {}\".format(imgName))\n",
    "        #sclassTag = imgName.split(\".\")[0].split(\"-\")[0] # 得到 类标签(数字)\n",
    "        #print(\"classTag: {}\".format(classTag))\n",
    "        dataLabel.append(label)\n",
    "        dataMat[i,:] = img2vector(imgName, 20)\n",
    "        \n",
    "    return dataMat, dataLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取训练数据\n",
    "def read_all_data():\n",
    "    #cName = ['1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "    #flist = \"./Images/TrainingSamples/0-{1:04d}.png\"\n",
    "    #flist = get_file_list(train_data_path)\n",
    "    flist = [ None ] * 200\n",
    "    flist_ = [ None ] * 200\n",
    "    for sample in range(0, TrainingSampleNum // ClassNum):\n",
    "        flist[sample] = TrainingDataFile.format(0, sample)\n",
    "    dataMat, dataLabel = read_and_convert(flist, 0)\n",
    "    for label in range(1, ClassNum):\n",
    "        for sample in range(0, TrainingSampleNum // ClassNum):\n",
    "            flist_[sample] = TrainingDataFile.format(label, sample)\n",
    "        dataMat_, dataLabel_ = read_and_convert(flist_, label)\n",
    "        dataMat = np.concatenate((dataMat, dataMat_), axis=0)\n",
    "        dataLabel = np.concatenate((dataLabel, dataLabel_), axis=0)\n",
    "    \n",
    "    #dataNum = dataMat.shape[0]\n",
    "    #dataMat = pca(dataMat, dataNum) #PCA\n",
    "    print(dataMat.shape)\n",
    "    print(len(dataLabel))\n",
    "    #np.set_printoptions(threshold=np.inf)\n",
    "    #print(dataMat)\n",
    "    return dataMat, dataLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "def create_svm(dataMat, dataLabel, decision):\n",
    "    clf = svm.SVC(C=2, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape=decision, degree=3, gamma='auto', kernel='rbf', \n",
    "                  max_iter=-1, probability=False, random_state=None, shrinking=True, tol=0.001, verbose=False)\n",
    "    clf.fit(dataMat, dataLabel)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataMat, dataLabel = read_all_data()\n",
    "#pca = decomposition.PCA(n_components = 300 )\n",
    "#New_dataMat = pca.fit(dataMat)\n",
    "#clf = create_svm(New_dataMat, dataLabel, 'ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对10个数字进行分类测试\n",
    "def main():\n",
    "    tflist = [ None ] * 1000\n",
    "    labelName = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "    tst = time.time()\n",
    "    allErrCount = 0\n",
    "    allErrorRate = 0.0\n",
    "    allScore = 0.0\n",
    "    results = np.zeros((ClassNum, ClassNum))\n",
    "    # 訓練データを読み込み\n",
    "    dataMat, dataLabel = read_all_data()\n",
    "    #PCA\n",
    "    pca = decomposition.PCA(n_components = 40).fit(dataMat)\n",
    "    New_dataMat = pca.transform(dataMat)\n",
    "    #SVM\n",
    "    clf = create_svm(New_dataMat, dataLabel, 'ovo')\n",
    "    #for tcn  in tcName:\n",
    "        #testPath = \"Mnist-image\\\\test\\\\\" + tcn\n",
    "        #print(\"class \" + tcn + \" path is: {}.\".format(testPath))\n",
    "        #tflist = get_file_list(testPath)\n",
    "        #tflist\n",
    "    #dataMat, dataLabel = read_all_data()\n",
    "    #clf = create_svm(dataMat, dataLabel, decision='ovr')\n",
    "    for label in range(0, ClassNum):\n",
    "        for sample in range(0, TestSampleNum // ClassNum):\n",
    "            tflist[sample] = TestDataFile.format(label, sample)\n",
    "        tdataMat, tdataLabel = read_and_convert(tflist, label)\n",
    "        print(\"test dataMat shape: {0}, test dataLabel len: {1} \".format(tdataMat.shape, len(tdataLabel)))\n",
    "        \n",
    "        #tdataNum = tdataMat.shape[0]\n",
    "        tdataMat = pca.transform(tdataMat)  #PCA\n",
    "        print(tdataMat.shape)\n",
    "        print(len(tdataLabel))\n",
    "        \n",
    "        #print(\"test dataLabel: {}\".format(len(tdataLabel)))\n",
    "        pre_st = time.time()\n",
    "        preResult = clf.predict(tdataMat)\n",
    "        pre_et = time.time()\n",
    "        print(\"Recognition  {0} spent {1:.4f}s.\".format(label, (pre_et-pre_st)))\n",
    "        #print(\"predict result: {}\".format(len(preResult)))\n",
    "        for x in preResult:\n",
    "            results[label, x] += 1 #Confusion matrix\n",
    "            \n",
    "        errCount = len([x for x in preResult if x!=label])\n",
    "        print(\"errorCount: {}.\".format(errCount))\n",
    "        allErrCount += errCount\n",
    "        score_st = time.time()\n",
    "        score = clf.score(tdataMat, tdataLabel)\n",
    "        score_et = time.time()\n",
    "        print(\"computing score spent {:.6f}s.\".format(score_et-score_st))\n",
    "        allScore += score\n",
    "        print(\"score: {:.6f}.\".format(score))\n",
    "        print(\"error rate is {:.6f}.\".format((1-score)))\n",
    "        print(\"---------------------------------------------------------\")\n",
    "\n",
    "\n",
    "    tet = time.time()\n",
    "    print(\"Testing All class total spent {:.6f}s.\".format(tet-tst))\n",
    "    #print(\"All error Count is: {}.\".format(allErrCount))\n",
    "    avgAccuracy = allScore/10.0\n",
    "    print(\"Average accuracy is: {:.6f}.\".format(avgAccuracy))\n",
    "    #print(\"Average error rate is: {:.6f}.\".format(1-avgAccuracy))\n",
    "    print(\"= Confusion matrix ===========\")\n",
    "    for t_label in range(0, ClassNum):\n",
    "        for m_label in range(0, ClassNum):\n",
    "            print(\"{:04g}, \".format(results[t_label, m_label]), end=\"\")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 784)\n",
      "2000\n",
      "test dataMat shape: (1000, 784), test dataLabel len: 1000 \n",
      "(1000, 40)\n",
      "1000\n",
      "Recognition  0 spent 0.0878s.\n",
      "errorCount: 1000.\n",
      "computing score spent 0.088986s.\n",
      "score: 0.000000.\n",
      "error rate is 1.000000.\n",
      "---------------------------------------------------------\n",
      "test dataMat shape: (1000, 784), test dataLabel len: 1000 \n",
      "(1000, 40)\n",
      "1000\n",
      "Recognition  1 spent 0.0880s.\n",
      "errorCount: 994.\n",
      "computing score spent 0.088134s.\n",
      "score: 0.006000.\n",
      "error rate is 0.994000.\n",
      "---------------------------------------------------------\n",
      "test dataMat shape: (1000, 784), test dataLabel len: 1000 \n",
      "(1000, 40)\n",
      "1000\n",
      "Recognition  2 spent 0.0882s.\n",
      "errorCount: 1000.\n",
      "computing score spent 0.087840s.\n",
      "score: 0.000000.\n",
      "error rate is 1.000000.\n",
      "---------------------------------------------------------\n",
      "test dataMat shape: (1000, 784), test dataLabel len: 1000 \n",
      "(1000, 40)\n",
      "1000\n",
      "Recognition  3 spent 0.0875s.\n",
      "errorCount: 1000.\n",
      "computing score spent 0.087947s.\n",
      "score: 0.000000.\n",
      "error rate is 1.000000.\n",
      "---------------------------------------------------------\n",
      "test dataMat shape: (1000, 784), test dataLabel len: 1000 \n",
      "(1000, 40)\n",
      "1000\n",
      "Recognition  4 spent 0.1230s.\n",
      "errorCount: 1000.\n",
      "computing score spent 0.105562s.\n",
      "score: 0.000000.\n",
      "error rate is 1.000000.\n",
      "---------------------------------------------------------\n",
      "test dataMat shape: (1000, 784), test dataLabel len: 1000 \n",
      "(1000, 40)\n",
      "1000\n",
      "Recognition  5 spent 0.0929s.\n",
      "errorCount: 1000.\n",
      "computing score spent 0.092989s.\n",
      "score: 0.000000.\n",
      "error rate is 1.000000.\n",
      "---------------------------------------------------------\n",
      "test dataMat shape: (1000, 784), test dataLabel len: 1000 \n",
      "(1000, 40)\n",
      "1000\n",
      "Recognition  6 spent 0.0882s.\n",
      "errorCount: 1000.\n",
      "computing score spent 0.089809s.\n",
      "score: 0.000000.\n",
      "error rate is 1.000000.\n",
      "---------------------------------------------------------\n",
      "test dataMat shape: (1000, 784), test dataLabel len: 1000 \n",
      "(1000, 40)\n",
      "1000\n",
      "Recognition  7 spent 0.1299s.\n",
      "errorCount: 1000.\n",
      "computing score spent 0.092477s.\n",
      "score: 0.000000.\n",
      "error rate is 1.000000.\n",
      "---------------------------------------------------------\n",
      "test dataMat shape: (1000, 784), test dataLabel len: 1000 \n",
      "(1000, 40)\n",
      "1000\n",
      "Recognition  8 spent 0.1077s.\n",
      "errorCount: 1000.\n",
      "computing score spent 0.089162s.\n",
      "score: 0.000000.\n",
      "error rate is 1.000000.\n",
      "---------------------------------------------------------\n",
      "test dataMat shape: (1000, 784), test dataLabel len: 1000 \n",
      "(1000, 40)\n",
      "1000\n",
      "Recognition  9 spent 0.0976s.\n",
      "errorCount: 0.\n",
      "computing score spent 0.093328s.\n",
      "score: 1.000000.\n",
      "error rate is 0.000000.\n",
      "---------------------------------------------------------\n",
      "Testing All class total spent 22.800215s.\n",
      "Average accuracy is: 0.100600.\n",
      "= Confusion matrix ===========\n",
      "0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 1000, \n",
      "0000, 0006, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0994, \n",
      "0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 1000, \n",
      "0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 1000, \n",
      "0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 1000, \n",
      "0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 1000, \n",
      "0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 1000, \n",
      "0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 1000, \n",
      "0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 1000, \n",
      "0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 1000, \n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
